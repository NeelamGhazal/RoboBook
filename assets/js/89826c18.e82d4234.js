"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[6458],{5824:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"module-3-isaac/chapter-5-domain-randomization","title":"Domain Randomization Techniques","description":"Learning Objectives","source":"@site/docs/module-3-isaac/chapter-5-domain-randomization.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-5-domain-randomization","permalink":"/RoboBook/docs/module-3-isaac/chapter-5-domain-randomization","draft":false,"unlisted":false,"editUrl":"https://github.com/NeelamGhazal/RoboBook/tree/main/docs/module-3-isaac/chapter-5-domain-randomization.md","tags":[],"version":"current","sidebarPosition":16,"frontMatter":{"title":"Domain Randomization Techniques","sidebar_position":16},"sidebar":"textbookSidebar","previous":{"title":"Chapter 4: Sim-to-Real Transfer","permalink":"/RoboBook/docs/module-3-isaac/chapter-4-sim-to-real-principles"},"next":{"title":"Chapter 1: VLA Models Introduction","permalink":"/RoboBook/docs/module-4-vla/chapter-1-vla-introduction"}}');var r=i(4848),t=i(8453);const o={title:"Domain Randomization Techniques",sidebar_position:16},s="Domain Randomization Techniques",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Knowledge Prerequisites",id:"knowledge-prerequisites",level:3},{value:"Software Prerequisites",id:"software-prerequisites",level:3},{value:"Installation Verification",id:"installation-verification",level:3},{value:"Introduction",id:"introduction",level:2},{value:"Theory",id:"theory",level:2},{value:"Domain Randomization Categories",id:"domain-randomization-categories",level:3},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physical Domain Randomization",id:"physical-domain-randomization",level:3},{value:"Environmental Domain Randomization",id:"environmental-domain-randomization",level:3},{value:"Isaac Replicator for Domain Randomization",id:"isaac-replicator-for-domain-randomization",level:3},{value:"Randomization Strategies",id:"randomization-strategies",level:3},{value:"Evaluation Metrics",id:"evaluation-metrics",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Isaac Replicator Randomization Script (advanced_randomization.py)",id:"isaac-replicator-randomization-script-advanced_randomizationpy",level:3},{value:"Isaac Sim Domain Randomization Extension (domain_randomization_extension.py)",id:"isaac-sim-domain-randomization-extension-domain_randomization_extensionpy",level:3},{value:"Training Script with Domain Randomization (train_with_randomization.py)",id:"training-script-with-domain-randomization-train_with_randomizationpy",level:3},{value:"Running the Example",id:"running-the-example",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: Texture Randomization",id:"exercise-1-texture-randomization",level:3},{value:"Exercise 2: Physics Parameter Tuning",id:"exercise-2-physics-parameter-tuning",level:3},{value:"Exercise 3: Curriculum Learning",id:"exercise-3-curriculum-learning",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"domain-randomization-techniques",children:"Domain Randomization Techniques"})}),"\n",(0,r.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Implement advanced domain randomization techniques for visual, physical, and environmental aspects"}),"\n",(0,r.jsx)(e.li,{children:"Apply texture and material randomization to improve visual transfer"}),"\n",(0,r.jsx)(e.li,{children:"Configure lighting and camera parameter randomization for robust perception"}),"\n",(0,r.jsx)(e.li,{children:"Tune physics parameters for accurate dynamics transfer"}),"\n",(0,r.jsx)(e.li,{children:"Evaluate and optimize domain randomization strategies for specific applications"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(e.h3,{id:"knowledge-prerequisites",children:"Knowledge Prerequisites"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS 2 Fundamentals"}),": Understanding of nodes, topics, and message types (Module 1)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Simulation Concepts"}),": Understanding of Gazebo and Isaac simulation (Module 2-3)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sim-to-Real Transfer"}),": Understanding of reality gap and transfer principles (Module 3, Chapter 4)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Computer Vision"}),": Understanding of image processing and perception algorithms"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Physics Simulation"}),": Understanding of dynamics and contact models"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"software-prerequisites",children:"Software Prerequisites"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Operating System"}),": Ubuntu 22.04 LTS with ROS 2 Humble Hawksbill"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Isaac Sim"}),": NVIDIA Isaac Sim with domain randomization extensions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Python"}),": Version 3.10 or higher"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Graphics Libraries"}),": OpenGL, USD (Universal Scene Description) support"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Machine Learning Libraries"}),": PyTorch, TensorFlow for training with randomized data"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Visualization Tools"}),": Isaac Sim viewer, RViz2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Terminal"}),": Bash shell access"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"installation-verification",children:"Installation Verification"}),"\n",(0,r.jsx)(e.p,{children:"Verify your domain randomization environment:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'# Check Isaac Sim domain randomization extensions\n# Isaac Sim should have domain randomization extension available\n\n# Check USD support\npython3 -c "from pxr import Usd, Sdf, Gf; print(\'USD libraries available\')"\n\n# Check Isaac extensions\nisaac-sim --ext-path /path/to/extensions --summary\n\n# Check for randomization packages\npython3 -c "import omni.replicator.core as rep; print(\'Replicator available\')" 2>/dev/null || echo "Isaac Replicator may not be installed"\n'})}),"\n",(0,r.jsx)(e.p,{children:"Expected output: Available USD libraries, Isaac extensions, and domain randomization capabilities."}),"\n",(0,r.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(e.p,{children:"In the previous chapter, we explored the fundamental principles of sim-to-real transfer and domain randomization. Now we'll dive deeper into advanced domain randomization techniques that can significantly improve the transfer success of learned policies from simulation to reality. Domain randomization is a powerful technique that involves systematically varying simulation parameters to make policies robust to the differences between simulation and reality."}),"\n",(0,r.jsx)(e.p,{children:"Think of domain randomization like training a student in multiple classrooms with different lighting, furniture arrangements, and noise levels. When that student encounters a new classroom, they can adapt more easily because they've already experienced a wide variety of conditions. Similarly, domain randomization exposes policies to a broad range of randomized conditions during training, making them robust to the inevitable differences between simulation and reality."}),"\n",(0,r.jsx)(e.p,{children:"In Physical AI systems, domain randomization is particularly effective because it addresses the reality gap without requiring perfect simulation fidelity. Rather than spending extensive time making simulations perfectly realistic, domain randomization makes policies robust to variations in visual appearance, physics parameters, and environmental conditions. This approach has proven successful in various robotics tasks, from manipulation to navigation to perception."}),"\n",(0,r.jsx)(e.p,{children:"In this chapter, we'll explore advanced techniques for randomizing textures, lighting, materials, physics parameters, and environmental conditions. We'll learn to implement these techniques in Isaac Sim and evaluate their effectiveness for improving sim-to-real transfer performance."}),"\n",(0,r.jsx)(e.h2,{id:"theory",children:"Theory"}),"\n",(0,r.jsx)(e.h3,{id:"domain-randomization-categories",children:"Domain Randomization Categories"}),"\n",(0,r.jsx)(e.p,{children:"Domain randomization can be categorized into several types:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Visual Randomization"}),": Randomizing appearance-related parameters"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Physical Randomization"}),": Randomizing physics and dynamics parameters"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Environmental Randomization"}),": Randomizing scene layout and conditions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensor Randomization"}),": Randomizing sensor models and noise characteristics"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,r.jsx)(e.p,{children:"Visual randomization addresses the appearance differences between simulation and reality:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Texture Randomization"}),": Varying surface textures, colors, and patterns"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Material Properties"}),": Randomizing roughness, metallic, specular, and emission properties"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Lighting Conditions"}),": Randomizing light positions, intensities, and colors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Camera Parameters"}),": Randomizing focal length, distortion, and sensor noise"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Post-Processing Effects"}),": Randomizing bloom, vignette, and other effects"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"physical-domain-randomization",children:"Physical Domain Randomization"}),"\n",(0,r.jsx)(e.p,{children:"Physical randomization addresses dynamics differences:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Mass Properties"}),": Randomizing mass, center of mass, and inertia tensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Friction Parameters"}),": Randomizing static and dynamic friction coefficients"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Contact Properties"}),": Randomizing restitution and damping coefficients"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actuator Characteristics"}),": Randomizing torque limits, response times, and noise"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Dynamics Parameters"}),": Randomizing damping and stiffness parameters"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"environmental-domain-randomization",children:"Environmental Domain Randomization"}),"\n",(0,r.jsx)(e.p,{children:"Environmental randomization addresses scene differences:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Object Placement"}),": Randomizing object positions and orientations"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Scene Layout"}),": Randomizing room layouts, obstacle positions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Weather Conditions"}),": Randomizing fog, rain, and atmospheric effects"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Background Variation"}),": Randomizing backgrounds and distractors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Temporal Variation"}),": Randomizing day/night cycles and lighting changes"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"isaac-replicator-for-domain-randomization",children:"Isaac Replicator for Domain Randomization"}),"\n",(0,r.jsx)(e.p,{children:"Isaac Replicator provides powerful tools for domain randomization:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-mermaid",children:'%%{title: "Isaac Replicator Architecture"}%%\ngraph TD\n    A[Training Loop] --\x3e B[Isaac Sim Scene]\n    B --\x3e C[Randomization Pipeline]\n    C --\x3e D[Visual Randomization]\n    C --\x3e E[Physical Randomization]\n    C --\x3e F[Environmental Randomization]\n\n    D --\x3e G[Texture Variations]\n    D --\x3e H[Lighting Variations]\n    D --\x3e I[Camera Effects]\n\n    E --\x3e J[Mass Variations]\n    E --\x3e K[Friction Variations]\n    E --\x3e L[Dynamics Variations]\n\n    F --\x3e M[Object Placement]\n    F --\x3e N[Scene Layout]\n    F --\x3e O[Background Variations]\n\n    G --\x3e P[Trained Policy]\n    H --\x3e P\n    I --\x3e P\n    J --\x3e P\n    K --\x3e P\n    L --\x3e P\n    M --\x3e P\n    N --\x3e P\n    O --\x3e P\n\n    P --\x3e Q[Improved Transfer]\n'})}),"\n",(0,r.jsx)(e.h3,{id:"randomization-strategies",children:"Randomization Strategies"}),"\n",(0,r.jsx)(e.p,{children:"Effective domain randomization requires careful strategy:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Uniform Randomization"}),": Randomizing parameters uniformly across ranges"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Curriculum Randomization"}),": Starting with narrow ranges and expanding"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Adversarial Randomization"}),": Using adversarial techniques to find difficult cases"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Importance Sampling"}),": Focusing randomization on important parameters"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"evaluation-metrics",children:"Evaluation Metrics"}),"\n",(0,r.jsx)(e.p,{children:"Domain randomization effectiveness is measured by:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Transfer Gap"}),": Difference in performance between sim and real"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Robustness"}),": Performance variance across different conditions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sample Efficiency"}),": Training samples required to achieve performance"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Generalization"}),": Performance on unseen conditions"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,r.jsx)(e.p,{children:"Let's implement advanced domain randomization techniques with Isaac Sim:"}),"\n",(0,r.jsx)(e.h3,{id:"isaac-replicator-randomization-script-advanced_randomizationpy",children:"Isaac Replicator Randomization Script (advanced_randomization.py)"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import omni\nfrom pxr import Gf, Sdf, UsdGeom, UsdShade\nimport carb\nimport numpy as np\nimport random\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.prims import get_prim_at_path, define_prim\nfrom omni.isaac.core.utils.stage import get_stage_units\nfrom omni.replicator.core import random_colours\nimport omni.replicator.core as rep\n\n\nclass AdvancedDomainRandomizer:\n    """\n    Advanced domain randomization class using Isaac Replicator.\n    Implements visual, physical, and environmental randomization.\n    """\n\n    def __init__(self, world):\n        self.world = world\n        self.stage = omni.usd.get_context().get_stage()\n\n        # Randomization parameters\n        self.visual_params = {\n            \'light_intensity_range\': (0.3, 2.0),\n            \'light_color_temperature_range\': (3000, 8000),  # Kelvin\n            \'material_roughness_range\': (0.05, 0.95),\n            \'material_metallic_range\': (0.0, 0.8),\n            \'texture_scale_range\': (0.5, 2.0),\n        }\n\n        self.physical_params = {\n            \'friction_range\': (0.1, 1.0),\n            \'restitution_range\': (0.0, 0.5),\n            \'mass_multiplier_range\': (0.8, 1.2),\n            \'damping_range\': (0.0, 0.1),\n        }\n\n        self.environmental_params = {\n            \'object_position_jitter\': 0.2,\n            \'object_rotation_jitter\': 0.2,\n            \'background_color_range\': (0.0, 1.0),\n        }\n\n    def setup_replicator_randomization(self):\n        """Setup Isaac Replicator for domain randomization."""\n        # Create Replicator stream\n        writer = rep.WriterRegistry.get("BasicWriter")\n        writer.initialize(output_dir="./randomized_dataset", rgb=True, depth=True, semantic_segmentation=True)\n\n        print("Replicator randomization setup completed")\n        return writer\n\n    def randomize_visual_attributes(self):\n        """Randomize visual attributes of objects and environment."""\n        # Get all materials in the scene\n        material_prims = []\n        for prim in self.stage.TraverseAll():\n            if prim.IsA(UsdShade.Material):\n                material_prims.append(prim)\n\n        for material_prim in material_prims:\n            # Randomize material properties using Replicator\n            material = UsdShade.Material(material_prim)\n\n            # Get the surface shader\n            surface_shader = material.GetSurfaceOutput()\n            if surface_shader:\n                # Randomize roughness\n                roughness_range = self.visual_params[\'material_roughness_range\']\n                new_roughness = random.uniform(*roughness_range)\n\n                # Find and set roughness input\n                for input_name in material.GetShaderInputs():\n                    if \'roughness\' in input_name.GetBaseName().lower():\n                        input_name.Set(new_roughness)\n                        break\n\n                # Randomize metallic\n                metallic_range = self.visual_params[\'material_metallic_range\']\n                new_metallic = random.uniform(*metallic_range)\n\n                for input_name in material.GetShaderInputs():\n                    if \'metallic\' in input_name.GetBaseName().lower():\n                        input_name.Set(new_metallic)\n                        break\n\n    def randomize_textures_and_appearance(self):\n        """Randomize textures and appearance properties."""\n        # This would use Isaac Replicator\'s texture randomization\n        # For this example, we\'ll simulate the process\n\n        # Get all mesh prims in the scene\n        mesh_prims = []\n        for prim in self.stage.TraverseAll():\n            if prim.IsA(UsdGeom.Mesh):\n                mesh_prims.append(prim)\n\n        for mesh_prim in mesh_prims:\n            # In real implementation, this would connect to Replicator\'s texture system\n            # For simulation, we\'ll just log what would happen\n            mesh_geom = UsdGeom.Mesh(mesh_prim)\n            prim_name = mesh_prim.GetName()\n\n            # Simulate texture assignment randomization\n            texture_options = [\n                "wood_grain", "metal_plate", "concrete", "tile", "carpet",\n                "plastic", "glass", "fabric", "stone", "grass"\n            ]\n            random_texture = random.choice(texture_options)\n\n            print(f"Assigned random texture \'{random_texture}\' to {prim_name}")\n\n    def randomize_lighting_conditions(self):\n        """Randomize lighting conditions in the scene."""\n        # Get all light prims in the scene\n        light_prims = []\n        for prim in self.stage.TraverseAll():\n            if prim.GetTypeName() in [\'DistantLight\', \'SphereLight\', \'RectLight\', \'DomeLight\']:\n                light_prims.append(prim)\n\n        for light_prim in light_prims:\n            light_api = UsdLux.LightAPI(light_prim)\n\n            # Randomize light intensity\n            intensity_range = self.visual_params[\'light_intensity_range\']\n            new_intensity = random.uniform(*intensity_range)\n            light_api.GetIntensityAttr().Set(new_intensity)\n\n            # Randomize light color temperature\n            temp_range = self.visual_params[\'light_color_temperature_range\']\n            new_temp = random.uniform(*temp_range)\n\n            # Convert temperature to RGB approximation\n            rgb = self.temperature_to_rgb(new_temp)\n            light_api.GetColorAttr().Set(Gf.Vec3f(*rgb))\n\n    def temperature_to_rgb(self, kelvin):\n        """Convert temperature in Kelvin to RGB color."""\n        temp = kelvin / 100\n        r, g, b = 0, 0, 0\n\n        # Red\n        if temp <= 66:\n            r = 255\n        else:\n            r = temp - 60\n            r = 329.698727446 * (r ** -0.1332047592)\n            r = max(0, min(255, r))\n\n        # Green\n        if temp <= 66:\n            g = temp\n            g = 99.4708025861 * np.log(g) - 161.1195681661\n        else:\n            g = temp - 60\n            g = 288.1221695283 * (g ** -0.0755148492)\n        g = max(0, min(255, g))\n\n        # Blue\n        if temp >= 66:\n            b = 255\n        elif temp <= 19:\n            b = 0\n        else:\n            b = temp - 10\n            b = 138.5177312231 * np.log(b) - 305.0447927307\n            b = max(0, min(255, b))\n\n        return (r/255.0, g/255.0, b/255.0)\n\n    def randomize_physics_parameters(self):\n        """Randomize physical parameters of objects."""\n        # Get all rigid bodies in the scene\n        rigid_body_prims = []\n        for prim in self.stage.TraverseAll():\n            if prim.HasAPI(UsdPhysics.RigidBodyAPI):\n                rigid_body_prims.append(prim)\n\n        for body_prim in rigid_body_prims:\n            # Randomize friction\n            friction_range = self.physical_params[\'friction_range\']\n            new_friction = random.uniform(*friction_range)\n\n            # In real implementation, this would set physics attributes\n            print(f"Set friction for {body_prim.GetName()} to {new_friction:.3f}")\n\n            # Randomize mass\n            mass_range = self.physical_params[\'mass_multiplier_range\']\n            mass_multiplier = random.uniform(*mass_range)\n\n            print(f"Set mass multiplier for {body_prim.GetName()} to {mass_multiplier:.3f}")\n\n    def randomize_environment_layout(self):\n        """Randomize environmental layout and object positions."""\n        # Get all movable objects in the scene\n        movable_objects = []\n        for prim in self.stage.TraverseAll():\n            if (prim.IsA(UsdGeom.Xformable) and\n                prim.GetName() not in [\'ground_plane\', \'environment\', \'floor\']):\n                movable_objects.append(prim)\n\n        for obj_prim in movable_objects:\n            # Get current position\n            xformable = UsdGeom.Xformable(obj_prim)\n            transform_ops = xformable.GetOrderedXformOps()\n\n            for op in transform_ops:\n                if op.GetOpType() == UsdGeom.XformOp.TypeTranslate:\n                    current_pos = op.Get()\n\n                    # Add random jitter\n                    jitter = self.environmental_params[\'object_position_jitter\']\n                    new_x = current_pos[0] + random.uniform(-jitter, jitter)\n                    new_y = current_pos[1] + random.uniform(-jitter, jitter)\n                    new_z = current_pos[2] + random.uniform(-jitter, jitter)\n\n                    op.Set(Gf.Vec3d(new_x, new_y, new_z))\n                    break\n\n    def apply_advanced_randomization(self):\n        """Apply all advanced randomization techniques."""\n        print("Applying advanced domain randomization...")\n\n        self.randomize_visual_attributes()\n        self.randomize_textures_and_appearance()\n        self.randomize_lighting_conditions()\n        self.randomize_physics_parameters()\n        self.randomize_environment_layout()\n\n        print("Advanced domain randomization applied successfully")\n\n    def create_curriculum_randomization(self, epoch, max_epochs):\n        """Create curriculum-based randomization that increases difficulty."""\n        # Scale randomization ranges based on training progress\n        progress = epoch / max_epochs\n\n        # Increase randomization range as training progresses\n        scale_factor = 0.1 + 0.9 * progress  # Start small, grow to full range\n\n        # Update parameter ranges\n        original_intensity_range = self.visual_params[\'light_intensity_range\']\n        self.visual_params[\'light_intensity_range\'] = (\n            original_intensity_range[0] * (1 - 0.5 * progress),\n            original_intensity_range[1] * (1 + 0.5 * progress)\n        )\n\n        print(f"Curriculum randomization at epoch {epoch}/{max_epochs}, scale: {scale_factor:.2f}")\n\n\nclass DomainRandomizationTrainingManager:\n    """\n    Manager class for domain randomization during training.\n    Handles randomization scheduling and evaluation.\n    """\n\n    def __init__(self):\n        self.epoch = 0\n        self.max_epochs = 1000\n        self.randomization_frequency = 10  # Apply randomization every N episodes\n        self.episode_count = 0\n        self.success_history = []\n\n        print("Domain randomization training manager initialized")\n\n    def schedule_randomization(self):\n        """Schedule randomization based on training progress."""\n        if self.episode_count % self.randomization_frequency == 0:\n            print(f"Applying domain randomization at episode {self.episode_count}")\n            return True\n        return False\n\n    def evaluate_randomization_effectiveness(self):\n        """Evaluate how effective the randomization is."""\n        if len(self.success_history) < 20:\n            return 0.5  # Default effectiveness if insufficient data\n\n        # Calculate recent success rate\n        recent_successes = sum(self.success_history[-20:])\n        recent_rate = recent_successes / 20.0\n\n        # Calculate overall trend\n        if len(self.success_history) > 40:\n            earlier_successes = sum(self.success_history[-40:-20])\n            earlier_rate = earlier_successes / 20.0\n            trend = recent_rate - earlier_rate\n        else:\n            trend = 0.0\n\n        effectiveness = {\n            \'recent_success_rate\': recent_rate,\n            \'trend\': trend,\n            \'overall_performance\': sum(self.success_history) / len(self.success_history)\n        }\n\n        return effectiveness\n\n    def adaptive_randomization(self, performance_metrics):\n        """Adjust randomization strategy based on performance."""\n        if performance_metrics[\'trend\'] < -0.05:  # Performance degrading\n            # Reduce randomization intensity\n            self.randomization_frequency *= 1.1\n            print(f"Reducing randomization frequency to {self.randomization_frequency:.1f}")\n        elif performance_metrics[\'trend\'] > 0.05:  # Performance improving\n            # Increase randomization intensity\n            self.randomization_frequency = max(5, self.randomization_frequency * 0.9)\n            print(f"Increasing randomization frequency to {self.randomization_frequency:.1f}")\n\n    def record_episode_result(self, success, performance_score):\n        """Record the result of an episode."""\n        self.success_history.append(success)\n        self.episode_count += 1\n\n        # Evaluate and adapt randomization strategy\n        if len(self.success_history) >= 20:\n            metrics = self.evaluate_randomization_effectiveness()\n            self.adaptive_randomization(metrics)\n\n        if self.episode_count % 50 == 0:\n            avg_success = sum(self.success_history[-50:]) / min(50, len(self.success_history))\n            print(f"Episode {self.episode_count}: Recent success rate: {avg_success:.3f}")\n\n\ndef main():\n    """Main function demonstrating advanced domain randomization."""\n    print("=== Advanced Domain Randomization Demo ===\\n")\n\n    # In Isaac Sim, you would initialize the world\n    # world = World(stage_units_in_meters=1.0)\n\n    # Create randomization manager\n    manager = DomainRandomizationTrainingManager()\n\n    # Create domain randomizer\n    # randomizer = AdvancedDomainRandomizer(world)\n\n    # Simulate training loop\n    print("Simulating training loop with domain randomization...\\n")\n\n    for epoch in range(10):  # Simulate 10 epochs\n        print(f"Epoch {epoch + 1}/10")\n\n        # Apply curriculum randomization\n        # randomizer.create_curriculum_randomization(epoch, 10)\n\n        # Simulate episodes\n        for episode in range(20):\n            # Check if randomization should be applied\n            if manager.schedule_randomization():\n                # In real implementation: randomizer.apply_advanced_randomization()\n                print(f"  Episode {episode + 1}: Applied domain randomization")\n            else:\n                print(f"  Episode {episode + 1}: Normal training")\n\n            # Simulate episode result\n            import random\n            success = random.random() > 0.3  # 70% success rate\n            performance_score = random.uniform(0.5, 1.0)\n\n            # Record result\n            manager.record_episode_result(success, performance_score)\n\n        print()\n\n    print("Advanced domain randomization demo completed!")\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"isaac-sim-domain-randomization-extension-domain_randomization_extensionpy",children:"Isaac Sim Domain Randomization Extension (domain_randomization_extension.py)"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import omni\nfrom pxr import Gf, Sdf, UsdGeom\nimport carb\nimport numpy as np\nimport omni.replicator.core as rep\nfrom omgi.isaac.core import World\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.kit.menu.utils import MenuItemDescription, add_menu_items, remove_menu_items\n\n\nclass DomainRandomizationExtension:\n    """\n    Isaac Sim extension for domain randomization.\n    Provides GUI controls and automated randomization.\n    """\n\n    def __init__(self):\n        self.world = None\n        self.randomizer = None\n        self.enabled = False\n        self.randomization_frequency = 100  # randomize every 100 steps\n        self.step_count = 0\n        self.recording_mode = False\n        self.dataset_path = "./randomized_dataset"\n\n        # GUI parameters\n        self.visual_randomization_enabled = True\n        self.physical_randomization_enabled = True\n        self.environmental_randomization_enabled = True\n\n        print("Domain randomization extension initialized")\n\n    def setup_extension(self, world):\n        """Setup the domain randomization extension."""\n        self.world = world\n        self.randomizer = AdvancedDomainRandomizer(world)\n\n        # Setup replicator for dataset generation\n        self.setup_replicator()\n\n        print("Domain randomization extension setup completed")\n\n    def setup_replicator(self):\n        """Setup Isaac Replicator for synthetic data generation."""\n        # Define cameras for data collection\n        camera_paths = []\n        for prim in self.world.stage.TraverseAll():\n            if prim.IsA(UsdGeom.Camera):\n                camera_paths.append(str(prim.GetPath()))\n\n        if camera_paths:\n            # Create Replicator annotators\n            rep.create.annotators(\n                camera_paths=camera_paths,\n                annotators=["rgb", "depth", "instance_segmentation", "bounding_box_2d_tight"]\n            )\n\n            print(f"Setup Replicator with {len(camera_paths)} cameras")\n\n    def on_step(self, step_size):\n        """Called on each simulation step."""\n        self.step_count += 1\n\n        if self.enabled and self.step_count % self.randomization_frequency == 0:\n            self.apply_domain_randomization()\n            print(f"Applied domain randomization at step {self.step_count}")\n\n    def apply_domain_randomization(self):\n        """Apply domain randomization based on enabled categories."""\n        if self.visual_randomization_enabled:\n            self.randomizer.randomize_visual_attributes()\n            self.randomizer.randomize_textures_and_appearance()\n            self.randomizer.randomize_lighting_conditions()\n\n        if self.physical_randomization_enabled:\n            self.randomizer.randomize_physics_parameters()\n\n        if self.environmental_randomization_enabled:\n            self.randomizer.randomize_environment_layout()\n\n    def enable_randomization(self):\n        """Enable domain randomization."""\n        self.enabled = True\n        print("Domain randomization enabled")\n\n    def disable_randomization(self):\n        """Disable domain randomization."""\n        self.enabled = False\n        print("Domain randomization disabled")\n\n    def set_randomization_frequency(self, frequency):\n        """Set how often randomization is applied."""\n        self.randomization_frequency = frequency\n        print(f"Randomization frequency set to {frequency} steps")\n\n    def start_recording_dataset(self, output_path=None):\n        """Start recording synthetic dataset."""\n        if output_path:\n            self.dataset_path = output_path\n\n        self.recording_mode = True\n        print(f"Started recording dataset to {self.dataset_path}")\n\n    def stop_recording_dataset(self):\n        """Stop recording synthetic dataset."""\n        self.recording_mode = False\n        print("Stopped recording dataset")\n\n    def get_randomization_stats(self):\n        """Get statistics about randomization."""\n        stats = {\n            \'enabled\': self.enabled,\n            \'frequency\': self.randomization_frequency,\n            \'steps_since_randomization\': self.step_count % self.randomization_frequency,\n            \'total_steps\': self.step_count,\n            \'recording_active\': self.recording_mode,\n            \'dataset_path\': self.dataset_path,\n            \'categories_enabled\': {\n                \'visual\': self.visual_randomization_enabled,\n                \'physical\': self.physical_randomization_enabled,\n                \'environmental\': self.environmental_randomization_enabled\n            }\n        }\n        return stats\n\n\n# Example configuration for domain randomization\nDOMAIN_RANDOMIZATION_CONFIG = {\n    "visual": {\n        "enabled": True,\n        "texture_randomization": {\n            "probability": 0.8,\n            "texture_library": [\n                "wood_grain", "metal_plate", "concrete", "tile", "carpet",\n                "plastic", "glass", "fabric", "stone", "grass", "water", "sand"\n            ],\n            "scale_range": [0.5, 2.0],\n            "rotation_range": [0, 360]\n        },\n        "lighting_randomization": {\n            "enabled": True,\n            "intensity_range": [0.3, 2.0],\n            "temperature_range": [3000, 8000],\n            "position_jitter": 0.5\n        },\n        "material_randomization": {\n            "roughness_range": [0.05, 0.95],\n            "metallic_range": [0.0, 0.8],\n            "specular_range": [0.0, 1.0]\n        }\n    },\n    "physical": {\n        "enabled": True,\n        "dynamics_randomization": {\n            "mass_range": [0.8, 1.2],\n            "friction_range": [0.1, 1.0],\n            "restitution_range": [0.0, 0.5],\n            "damping_range": [0.0, 0.1]\n        },\n        "contact_randomization": {\n            "stiffness_range": [1e3, 1e6],\n            "dissipation_range": [0.0, 10.0]\n        }\n    },\n    "environmental": {\n        "enabled": True,\n        "layout_randomization": {\n            "object_position_jitter": 0.3,\n            "object_rotation_jitter": 0.3,\n            "background_variation": True\n        },\n        "weather_randomization": {\n            "fog_density_range": [0.0, 0.1],\n            "rain_probability": 0.1,\n            "wind_force_range": [0.0, 5.0]\n        }\n    },\n    "sensor": {\n        "enabled": True,\n        "camera_randomization": {\n            "focal_length_range": [18, 55],\n            "sensor_noise_std": 0.01,\n            "distortion_range": [0.0, 0.1]\n        },\n        "lidar_randomization": {\n            "noise_std": 0.02,\n            "dropout_rate": 0.01,\n            "range_accuracy": 0.01\n        }\n    }\n}\n\n\ndef apply_configured_randomization(config=DOMAIN_RANDOMIZATION_CONFIG):\n    """\n    Apply domain randomization based on configuration.\n    """\n    print("Applying configured domain randomization...")\n\n    for category, settings in config.items():\n        if settings.get(\'enabled\', False):\n            print(f"  - {category.capitalize()} randomization enabled")\n\n            for subcategory, params in settings.items():\n                if isinstance(params, dict) and subcategory != \'enabled\':\n                    print(f"    - {subcategory}: {params}")\n        else:\n            print(f"  - {category.capitalize()} randomization disabled")\n\n\ndef main():\n    """Main function for domain randomization extension."""\n    print("=== Isaac Sim Domain Randomization Extension ===\\n")\n\n    # Show configuration\n    print("Domain Randomization Configuration:")\n    import json\n    print(json.dumps(DOMAIN_RANDOMIZATION_CONFIG, indent=2))\n\n    print("\\nApplying configuration...")\n    apply_configured_randomization()\n\n    print("\\nDomain randomization extension ready!")\n    print("Enable through Isaac Sim extension manager or API.")\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"training-script-with-domain-randomization-train_with_randomizationpy",children:"Training Script with Domain Randomization (train_with_randomization.py)"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, LaserScan\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom std_msgs.msg import Bool, Float32\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import deque\nimport random\n\n\nclass DomainRandomizationTrainer(Node):\n    """\n    Node that implements training with domain randomization.\n    Demonstrates how to integrate randomization into training loops.\n    """\n\n    def __init__(self):\n        super().__init__(\'domain_randomization_trainer\')\n\n        # Training parameters\n        self.learning_rate = 1e-4\n        self.batch_size = 32\n        self.gamma = 0.99\n        self.epsilon = 1.0\n        self.epsilon_decay = 0.995\n        self.epsilon_min = 0.01\n\n        # Randomization parameters\n        self.randomization_enabled = True\n        self.randomization_frequency = 100  # Apply randomization every N steps\n        self.step_count = 0\n\n        # Networks\n        self.policy_network = self.create_policy_network()\n        self.target_network = self.create_policy_network()\n        self.optimizer = optim.Adam(self.policy_network.parameters(), lr=self.learning_rate)\n\n        # Experience replay\n        self.memory = deque(maxlen=10000)\n\n        # Publishers and subscribers\n        self.observation_sub = self.create_subscription(\n            Image, \'/camera/image\', self.observation_callback, 10\n        )\n\n        self.laser_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.laser_callback, 10\n        )\n\n        self.action_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.reward_pub = self.create_publisher(Float32, \'/reward\', 10)\n        self.done_pub = self.create_publisher(Bool, \'/episode_done\', 10)\n\n        # Training timer\n        self.train_timer = self.create_timer(0.1, self.train_step)\n\n        # Current state\n        self.current_observation = None\n        self.current_laser = None\n        self.current_reward = 0.0\n        self.episode_done = False\n\n        self.get_logger().info(\'Domain randomization trainer initialized\')\n\n    def create_policy_network(self):\n        """Create neural network for policy."""\n        class PolicyNetwork(nn.Module):\n            def __init__(self):\n                super().__init__()\n                # Convolutional layers for image processing\n                self.conv_layers = nn.Sequential(\n                    nn.Conv2d(3, 32, kernel_size=8, stride=4),\n                    nn.ReLU(),\n                    nn.Conv2d(32, 64, kernel_size=4, stride=2),\n                    nn.ReLU(),\n                    nn.Conv2d(64, 64, kernel_size=3, stride=1),\n                    nn.ReLU()\n                )\n\n                # Calculate conv output size (assuming 640x480 input)\n                conv_out_size = 64 * 79 * 59  # After convolutions\n\n                # Fully connected layers\n                self.fc_layers = nn.Sequential(\n                    nn.Linear(conv_out_size + 1080, 512),  # Image + laser features\n                    nn.ReLU(),\n                    nn.Linear(512, 256),\n                    nn.ReLU(),\n                    nn.Linear(256, 4)  # 4 actions: forward, backward, left, right\n                )\n\n            def forward(self, image, laser):\n                # Process image\n                img_features = self.conv_layers(image)\n                img_features = img_features.view(img_features.size(0), -1)\n\n                # Process laser\n                laser_features = laser\n\n                # Concatenate features\n                combined = torch.cat([img_features, laser_features], dim=1)\n\n                # Pass through FC layers\n                output = self.fc_layers(combined)\n                return output\n\n        return PolicyNetwork()\n\n    def observation_callback(self, msg):\n        """Process camera observation."""\n        # Convert ROS image to PyTorch tensor\n        # This is simplified - in practice, use cv_bridge\n        image_tensor = torch.randn(1, 3, 480, 640)  # Placeholder\n        self.current_observation = image_tensor\n\n    def laser_callback(self, msg):\n        """Process laser scan observation."""\n        # Convert laser scan to tensor\n        ranges = list(msg.ranges)\n        # Replace invalid ranges with max range\n        ranges = [r if 0 < r < float(\'inf\') else msg.range_max for r in ranges]\n        laser_tensor = torch.tensor(ranges, dtype=torch.float32).unsqueeze(0)\n        self.current_laser = laser_tensor\n\n    def compute_reward(self, action, observation, laser):\n        """Compute reward based on action and observations."""\n        # Simplified reward function\n        reward = 0.0\n\n        # Positive reward for moving forward safely\n        if action == 0:  # Forward action\n            min_distance = min(laser[0].tolist()) if laser is not None else 10.0\n            if min_distance > 0.5:  # Safe distance\n                reward += 1.0\n            else:\n                reward -= 5.0  # Collision penalty\n\n        # Negative reward for unsafe actions\n        if laser is not None:\n            min_distance = min(laser[0].tolist())\n            if min_distance < 0.3:\n                reward -= 10.0  # Very close to obstacle\n\n        return reward\n\n    def apply_domain_randomization(self):\n        """Apply domain randomization to simulation."""\n        # This would typically call into Isaac Sim\'s randomization API\n        # For simulation, we\'ll just log what would happen\n\n        # Visual randomization: change lighting, textures, colors\n        lighting_change = random.uniform(0.5, 2.0)\n        texture_variations = ["wood", "metal", "concrete", "grass"]\n        selected_texture = random.choice(texture_variations)\n\n        # Physical randomization: change friction, mass, dynamics\n        friction_change = random.uniform(0.1, 1.0)\n        mass_multiplier = random.uniform(0.8, 1.2)\n\n        # Environmental randomization: change object positions\n        object_jitter = random.uniform(0.0, 0.3)\n\n        self.get_logger().info(\n            f"Applied domain randomization: "\n            f"Lighting x{lighting_change:.2f}, "\n            f"Texture {selected_texture}, "\n            f"Friction x{friction_change:.2f}, "\n            f"Mass x{mass_multiplier:.2f}, "\n            f"Objects \xb1{object_jitter:.2f}m"\n        )\n\n    def select_action(self, state):\n        """Select action using epsilon-greedy policy."""\n        if np.random.rand() <= self.epsilon:\n            # Random action\n            return random.randint(0, 3)\n\n        # Greedy action\n        with torch.no_grad():\n            image, laser = state\n            q_values = self.policy_network(image, laser)\n            return q_values.argmax().item()\n\n    def train_step(self):\n        """Perform one training step."""\n        if (self.current_observation is not None and\n            self.current_laser is not None):\n\n            # Apply domain randomization periodically\n            if self.randomization_enabled and self.step_count % self.randomization_frequency == 0:\n                self.apply_domain_randomization()\n\n            # Select action\n            state = (self.current_observation, self.current_laser)\n            action = self.select_action(state)\n\n            # Compute reward (in real implementation, this would come from environment)\n            reward = self.compute_reward(action, self.current_observation, self.current_laser)\n\n            # Store experience\n            self.memory.append((state, action, reward, self.episode_done))\n\n            # Sample batch for training\n            if len(self.memory) > self.batch_size:\n                batch = random.sample(self.memory, self.batch_size)\n\n                # Unpack batch\n                states = [(s[0], s[1]) for s in batch]\n                actions = [s[2] for s in batch]\n                rewards = [s[3] for s in batch]\n\n                # Convert to tensors\n                batch_images = torch.stack([s[0] for s in states])\n                batch_lasers = torch.stack([s[1] for s in states])\n                batch_actions = torch.tensor(actions, dtype=torch.long)\n                batch_rewards = torch.tensor(rewards, dtype=torch.float32)\n\n                # Compute loss\n                q_values = self.policy_network(batch_images, batch_lasers)\n                predicted_q_values = q_values.gather(1, batch_actions.unsqueeze(1)).squeeze(1)\n\n                loss = nn.MSELoss()(predicted_q_values, batch_rewards)\n\n                # Backpropagate\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                # Update epsilon\n                if self.epsilon > self.epsilon_min:\n                    self.epsilon *= self.epsilon_decay\n\n                # Log training info\n                if self.step_count % 100 == 0:\n                    self.get_logger().info(\n                        f\'Training step {self.step_count}, \'\n                        f\'Loss: {loss.item():.4f}, \'\n                        f\'Epsilon: {self.epsilon:.3f}\'\n                    )\n\n            # Publish action\n            cmd_vel = Twist()\n            if action == 0:  # Forward\n                cmd_vel.linear.x = 0.5\n            elif action == 1:  # Backward\n                cmd_vel.linear.x = -0.3\n            elif action == 2:  # Left\n                cmd_vel.angular.z = 0.5\n            elif action == 3:  # Right\n                cmd_vel.angular.z = -0.5\n\n            self.action_pub.publish(cmd_vel)\n\n            # Update step count\n            self.step_count += 1\n\n    def save_model(self, filepath):\n        """Save trained model."""\n        torch.save({\n            \'policy_network_state_dict\': self.policy_network.state_dict(),\n            \'optimizer_state_dict\': self.optimizer.state_dict(),\n            \'epsilon\': self.epsilon,\n        }, filepath)\n        self.get_logger().info(f\'Model saved to {filepath}\')\n\n    def load_model(self, filepath):\n        """Load trained model."""\n        checkpoint = torch.load(filepath)\n        self.policy_network.load_state_dict(checkpoint[\'policy_network_state_dict\'])\n        self.optimizer.load_state_dict(checkpoint[\'optimizer_state_dict\'])\n        self.epsilon = checkpoint[\'epsilon\']\n        self.get_logger().info(f\'Model loaded from {filepath}\')\n\n\ndef main(args=None):\n    """Main function to run the domain randomization trainer."""\n    rclpy.init(args=args)\n\n    trainer = DomainRandomizationTrainer()\n\n    try:\n        rclpy.spin(trainer)\n    except KeyboardInterrupt:\n        trainer.get_logger().info(\'Training interrupted, saving model...\')\n        trainer.save_model(\'./domain_randomization_model.pth\')\n    finally:\n        trainer.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Expected Output:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"[INFO] [domain_randomization_trainer]: Domain randomization trainer initialized\n[INFO] [domain_randomization_trainer]: Applied domain randomization: Lighting x1.45, Texture grass, Friction x0.78, Mass x1.05, Objects \xb10.12m\n[INFO] [domain_randomization_trainer]: Training step 100, Loss: 0.2345, Epsilon: 0.905\n[INFO] [domain_randomization_trainer]: Training step 200, Loss: 0.1876, Epsilon: 0.860\n[INFO] [domain_randomization_trainer]: Applied domain randomization: Lighting x0.72, Texture metal, Friction x0.45, Mass x0.92, Objects \xb10.21m\n[INFO] [domain_randomization_trainer]: Training step 300, Loss: 0.1567, Epsilon: 0.817\n[INFO] [domain_randomization_trainer]: Training interrupted, saving model...\n[INFO] [domain_randomization_trainer]: Model saved to ./domain_randomization_model.pth\n"})}),"\n",(0,r.jsx)(e.h3,{id:"running-the-example",children:"Running the Example"}),"\n",(0,r.jsx)(e.p,{children:"To run these domain randomization examples:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Start Isaac Sim with domain randomization extension\n# Launch Isaac Sim through the Omniverse launcher\n# Enable the domain randomization extension in Extensions menu\n\n# Terminal 2: Run the domain randomization trainer\nsource /opt/ros/humble/setup.bash\nros2 run isaac_dr_examples domain_randomization_trainer\n\n# Terminal 3: Start Isaac Sim scene with objects to randomize\n# Load a scene with multiple objects, lights, and materials in Isaac Sim\n\n# Terminal 4: Monitor training progress\nsource /opt/ros/humble/setup.bash\nros2 topic echo /reward\nros2 topic echo /episode_done\n\n# Terminal 5: Visualize in RViz2\nsource /opt/ros/humble/setup.bash\nrviz2\n# Add displays for robot visualization and training metrics\n\n# Example of configuring domain randomization:\n# ros2 param set domain_randomization_trainer randomization_frequency 50\n# ros2 param set domain_randomization_trainer epsilon_decay 0.99\n"})}),"\n",(0,r.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsx)(e.h3,{id:"exercise-1-texture-randomization",children:"Exercise 1: Texture Randomization"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Task"}),": Implement advanced texture randomization for robot environments."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Steps"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Create a library of realistic textures for different surfaces"}),"\n",(0,r.jsx)(e.li,{children:"Implement procedural texture generation for infinite variation"}),"\n",(0,r.jsx)(e.li,{children:"Test the effect of texture randomization on visual perception"}),"\n",(0,r.jsx)(e.li,{children:"Evaluate transfer performance with and without texture randomization"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Success Criteria"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Texture library with 20+ diverse textures"}),"\n",(0,r.jsx)(e.li,{children:"Procedural generation algorithms implemented"}),"\n",(0,r.jsx)(e.li,{children:"Performance comparison showing improvement"}),"\n",(0,r.jsx)(e.li,{children:"Understanding of texture importance for transfer"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-2-physics-parameter-tuning",children:"Exercise 2: Physics Parameter Tuning"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Task"}),": Fine-tune physics parameters for optimal transfer performance."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Steps"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Identify key physics parameters affecting transfer (friction, mass, etc.)"}),"\n",(0,r.jsx)(e.li,{children:"Implement parameter optimization using Bayesian optimization"}),"\n",(0,r.jsx)(e.li,{children:"Test transfer performance across different parameter settings"}),"\n",(0,r.jsx)(e.li,{children:"Document optimal ranges for different robot types"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Success Criteria"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Key physics parameters identified and tunable"}),"\n",(0,r.jsx)(e.li,{children:"Optimization algorithm implemented and running"}),"\n",(0,r.jsx)(e.li,{children:"Performance improvements quantified"}),"\n",(0,r.jsx)(e.li,{children:"Guidelines for parameter selection created"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-3-curriculum-learning",children:"Exercise 3: Curriculum Learning"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Task"}),": Implement curriculum learning with progressive randomization."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Steps"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Design curriculum progression from low to high randomization"}),"\n",(0,r.jsx)(e.li,{children:"Implement automatic curriculum advancement based on performance"}),"\n",(0,r.jsx)(e.li,{children:"Test curriculum vs. uniform randomization approaches"}),"\n",(0,r.jsx)(e.li,{children:"Evaluate sample efficiency improvements"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Success Criteria"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Curriculum progression logic implemented"}),"\n",(0,r.jsx)(e.li,{children:"Automatic advancement based on performance metrics"}),"\n",(0,r.jsx)(e.li,{children:"Sample efficiency improvements demonstrated"}),"\n",(0,r.jsx)(e.li,{children:"Comparison with baseline approaches completed"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(e.p,{children:"Domain randomization is a powerful technique for improving sim-to-real transfer by making policies robust to differences between simulation and reality. We've explored advanced techniques for randomizing visual, physical, and environmental aspects of simulation. The combination of Isaac Replicator's synthetic data generation capabilities with systematic parameter randomization enables the creation of robust policies that perform well in real environments."}),"\n",(0,r.jsx)(e.p,{children:"We've implemented examples showing texture and material randomization, lighting condition variation, physics parameter tuning, and environmental layout randomization. The examples demonstrated how to integrate domain randomization into training loops and evaluate its effectiveness for improving transfer performance."}),"\n",(0,r.jsx)(e.p,{children:"Understanding domain randomization is crucial for Physical AI systems that need to operate effectively in real environments. The techniques enable efficient training in simulation while ensuring successful deployment on physical robots by making policies robust to the inevitable differences between simulated and real conditions."}),"\n",(0,r.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(e.p,{children:"With Module 3 complete, you now have comprehensive knowledge of NVIDIA Isaac, including simulation, SLAM, navigation, sim-to-real transfer, and domain randomization. You understand how to create realistic simulation environments, train robust policies, and transfer them to real robots."}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Next Module"}),": Module 4: Vision-Language-Action Models"]}),"\n",(0,r.jsx)(e.p,{children:"In Module 4, you'll learn about Vision-Language-Action (VLA) models that enable robots to understand natural language instructions and translate them into physical actions. You'll explore models like RT-2, \u03c00, and other foundation models that bridge the gap between human communication and robot execution."})]})}function c(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(m,{...n})}):m(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var a=i(6540);const r={},t=a.createContext(r);function o(n){const e=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),a.createElement(t.Provider,{value:e},n.children)}}}]);