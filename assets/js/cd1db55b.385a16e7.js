"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7275],{4655:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-2-simulation/chapter-1-simulation-intro","title":"Gazebo Physics Simulation Basics","description":"Learning Objectives","source":"@site/docs/module-2-simulation/chapter-1-simulation-intro.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/chapter-1-simulation-intro","permalink":"/RoboBook/docs/module-2-simulation/chapter-1-simulation-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/NeelamGhazal/RoboBook/tree/main/docs/module-2-simulation/chapter-1-simulation-intro.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Gazebo Physics Simulation Basics","sidebar_position":7},"sidebar":"textbookSidebar","previous":{"title":"Chapter 5: URDF Robot Description","permalink":"/RoboBook/docs/module-1-ros2/chapter-5-urdf-robot-description"},"next":{"title":"Chapter 2: LiDAR Integration","permalink":"/RoboBook/docs/module-2-simulation/chapter-2-lidar-integration"}}');var o=i(4848),t=i(8453);const r={title:"Gazebo Physics Simulation Basics",sidebar_position:7},l="Gazebo Physics Simulation Basics",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Knowledge Prerequisites",id:"knowledge-prerequisites",level:3},{value:"Software Prerequisites",id:"software-prerequisites",level:3},{value:"Installation Verification",id:"installation-verification",level:3},{value:"Introduction",id:"introduction",level:2},{value:"Theory",id:"theory",level:2},{value:"The Role of Simulation in Physical AI",id:"the-role-of-simulation-in-physical-ai",level:3},{value:"Simulation Approaches",id:"simulation-approaches",level:3},{value:"Physics-Accurate Simulation (Gazebo)",id:"physics-accurate-simulation-gazebo",level:4},{value:"High-Fidelity Graphics Simulation (Unity)",id:"high-fidelity-graphics-simulation-unity",level:4},{value:"Simulation-to-Reality Transfer",id:"simulation-to-reality-transfer",level:3},{value:"Simulation Ecosystems",id:"simulation-ecosystems",level:3},{value:"When to Use Simulation vs. Reality",id:"when-to-use-simulation-vs-reality",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Basic Gazebo World File (simple_world.sdf)",id:"basic-gazebo-world-file-simple_worldsdf",level:3},{value:"ROS 2 Node for Simulation Control",id:"ros-2-node-for-simulation-control",level:3},{value:"Launch File for Simulation (simulation_launch.py)",id:"launch-file-for-simulation-simulation_launchpy",level:3},{value:"Running the Simulation",id:"running-the-simulation",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Exercise 1: World Customization",id:"exercise-1-world-customization",level:3},{value:"Exercise 2: Sensor Integration",id:"exercise-2-sensor-integration",level:3},{value:"Exercise 3: Performance Comparison",id:"exercise-3-performance-comparison",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"gazebo-physics-simulation-basics",children:"Gazebo Physics Simulation Basics"})}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Explain the role and importance of simulation in Physical AI development"}),"\n",(0,o.jsx)(n.li,{children:"Compare different simulation approaches: physics-accurate vs. high-fidelity graphics"}),"\n",(0,o.jsx)(n.li,{children:"Identify when to use simulation vs. real hardware in development workflows"}),"\n",(0,o.jsx)(n.li,{children:"Understand the Gazebo and Unity ecosystems for robotics simulation"}),"\n",(0,o.jsx)(n.li,{children:"Describe the simulation-to-reality transfer challenges and solutions"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.h3,{id:"knowledge-prerequisites",children:"Knowledge Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Fundamentals"}),": Understanding of nodes, topics, services, and rclpy (Module 1)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Physical AI Concepts"}),": Understanding of Physical AI fundamentals from Chapter 0 (intro.md)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Python Programming"}),": Basic to intermediate understanding of Python programming"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robotics Concepts"}),": Basic understanding of robot kinematics and dynamics"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"software-prerequisites",children:"Software Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Operating System"}),": Ubuntu 22.04 LTS with ROS 2 Humble Hawksbill installed"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Python"}),": Version 3.10 or higher"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation Software"}),": Gazebo Garden (or Fortress) and Unity Hub (optional for Unity simulation)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Terminal"}),": Bash shell access"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"installation-verification",children:"Installation Verification"}),"\n",(0,o.jsx)(n.p,{children:"Verify your simulation environment:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Check Gazebo installation\ngz --version\n# or for older Gazebo versions\ngazebo --version\n\n# Check ROS 2 Gazebo packages\nros2 pkg executables gazebo_ros_pkgs\n"})}),"\n",(0,o.jsx)(n.p,{children:"Expected output: Version information for Gazebo and available ROS 2 packages."}),"\n",(0,o.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(n.p,{children:"In the previous module, we established the foundation of ROS 2 development: nodes for computation, topics for communication, services for synchronous requests, and URDF for robot description. These concepts form the software backbone of any Physical AI system. However, developing and testing robot algorithms directly on expensive hardware is risky, time-consuming, and often impractical. This is where simulation becomes essential."}),"\n",(0,o.jsx)(n.p,{children:'Think of simulation as a "parallel universe" for robots where you can safely test algorithms millions of times faster than real-world execution. Just as pilots train in flight simulators before flying real aircraft, roboticists use simulation environments to develop, test, and validate algorithms before deploying them on physical robots. In Physical AI, where safety, efficiency, and reliability are paramount, simulation enables rapid iteration without the constraints and risks of physical hardware.'}),"\n",(0,o.jsx)(n.p,{children:"Simulation accelerates development by orders of magnitude: what might take weeks of real-world testing can be completed in hours of simulation time. You can test edge cases that would be dangerous in reality (like robots falling down stairs), run thousands of experiments in parallel, and iterate on algorithms without wear and tear on mechanical components. Modern simulation tools like Gazebo and Unity provide physics-accurate environments that closely approximate real-world behavior, making the transition from simulation to reality increasingly seamless."}),"\n",(0,o.jsx)(n.p,{children:"In this module, we'll explore both physics-accurate simulation with Gazebo and high-fidelity graphics simulation with Unity. We'll learn how to create simulation environments, integrate them with ROS 2, and effectively transfer learned behaviors from simulation to real robots\u2014a process known as \"sim-to-real transfer.\""}),"\n",(0,o.jsx)(n.h2,{id:"theory",children:"Theory"}),"\n",(0,o.jsx)(n.h3,{id:"the-role-of-simulation-in-physical-ai",children:"The Role of Simulation in Physical AI"}),"\n",(0,o.jsx)(n.p,{children:"Simulation serves multiple critical functions in Physical AI development:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Algorithm Development"}),": Test and refine control algorithms, perception systems, and planning approaches in a controlled environment"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Safety Validation"}),": Verify that robot behaviors are safe before deployment on physical hardware"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Training Data Generation"}),": Create large datasets for machine learning models when real data is scarce"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Hardware Testing"}),": Evaluate robot designs and configurations without physical prototypes"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Multi-Robot Systems"}),": Test coordination between multiple robots without requiring multiple physical units"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"simulation-approaches",children:"Simulation Approaches"}),"\n",(0,o.jsx)(n.p,{children:"There are two primary approaches to robotics simulation, each with distinct advantages:"}),"\n",(0,o.jsx)(n.h4,{id:"physics-accurate-simulation-gazebo",children:"Physics-Accurate Simulation (Gazebo)"}),"\n",(0,o.jsx)(n.p,{children:"Physics-accurate simulation focuses on modeling the physical properties of the real world with high fidelity:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Dynamics"}),": Accurate modeling of forces, torques, collisions, and motion"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensor Simulation"}),": Realistic camera, LiDAR, IMU, and other sensor models"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Material Properties"}),": Accurate friction, elasticity, and interaction models"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Environment Physics"}),": Gravity, air resistance, and environmental effects"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mermaid",children:'%%{title: "Physics-Accurate Simulation Pipeline"}%%\ngraph TD\n    A[Robot Model + Physics] --\x3e B[Physics Engine]\n    B --\x3e C[Sensor Simulation]\n    C --\x3e D[ROS 2 Messages]\n    D --\x3e E[Algorithm Testing]\n    E --\x3e F[Sim-to-Real Transfer]\n'})}),"\n",(0,o.jsx)(n.h4,{id:"high-fidelity-graphics-simulation-unity",children:"High-Fidelity Graphics Simulation (Unity)"}),"\n",(0,o.jsx)(n.p,{children:"High-fidelity graphics simulation prioritizes visual realism for perception tasks:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Photorealistic Rendering"}),": Ray tracing, global illumination, and realistic materials"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Visual Complexity"}),": Detailed environments with complex lighting and textures"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Perception Training"}),": Generating synthetic datasets for computer vision models"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Human-Robot Interaction"}),": Realistic visualization for user studies"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mermaid",children:'%%{title: "High-Fidelity Graphics Simulation Pipeline"}%%\ngraph TD\n    A[3D Models + Materials] --\x3e B[Graphics Engine]\n    B --\x3e C[Ray Tracing & Lighting]\n    C --\x3e D[Synthetic Images]\n    D --\x3e E[Computer Vision Training]\n    E --\x3e F[Perception Validation]\n'})}),"\n",(0,o.jsx)(n.h3,{id:"simulation-to-reality-transfer",children:"Simulation-to-Reality Transfer"}),"\n",(0,o.jsx)(n.p,{children:'The ultimate goal of simulation is to develop behaviors that work effectively on real robots. This "sim-to-real transfer" faces several challenges:'}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Reality Gap"}),": Differences between simulated and real physics, sensors, and environments"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Domain Randomization"}),": Techniques to make algorithms robust to simulation imperfections"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"System Identification"}),": Calibrating simulation parameters to match real robot behavior"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Progressive Transfer"}),": Gradually moving from simulation to reality with increasing complexity"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"simulation-ecosystems",children:"Simulation Ecosystems"}),"\n",(0,o.jsx)(n.p,{children:"The robotics simulation landscape includes several complementary tools:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Gazebo"}),": Physics-accurate simulation with ROS 2 integration"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Unity"}),": High-fidelity graphics for perception tasks"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Webots"}),": All-in-one robotics simulator with built-in controllers"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"PyBullet"}),": Python-friendly physics simulation for research"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"NVIDIA Isaac Sim"}),": GPU-accelerated simulation with RTX rendering"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"when-to-use-simulation-vs-reality",children:"When to Use Simulation vs. Reality"}),"\n",(0,o.jsx)(n.p,{children:"Simulation is most valuable when:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Testing dangerous or destructive scenarios"}),"\n",(0,o.jsx)(n.li,{children:"Running large-scale experiments"}),"\n",(0,o.jsx)(n.li,{children:"Training machine learning models"}),"\n",(0,o.jsx)(n.li,{children:"Validating safety-critical behaviors"}),"\n",(0,o.jsx)(n.li,{children:"Developing in parallel with hardware development"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Real hardware is essential when:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Validating sensor accuracy"}),"\n",(0,o.jsx)(n.li,{children:"Testing material interactions"}),"\n",(0,o.jsx)(n.li,{children:"Evaluating system integration"}),"\n",(0,o.jsx)(n.li,{children:"Measuring performance under real conditions"}),"\n",(0,o.jsx)(n.li,{children:"Conducting user studies"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,o.jsx)(n.p,{children:"Let's create a simple simulation environment that demonstrates the integration between ROS 2 and Gazebo:"}),"\n",(0,o.jsx)(n.h3,{id:"basic-gazebo-world-file-simple_worldsdf",children:"Basic Gazebo World File (simple_world.sdf)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0" ?>\n<sdf version="1.7">\n  <world name="simple_world">\n    \x3c!-- Include a ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Include the sun --\x3e\n    <include>\n      <uri>model://sun</uri>\n    </include>\n\n    \x3c!-- Add a simple box obstacle --\x3e\n    <model name="box_obstacle">\n      <pose>2 0 0.5 0 0 0</pose>\n      <link name="box_link">\n        <collision name="box_collision">\n          <geometry>\n            <box>\n              <size>1 1 1</size>\n            </box>\n          </geometry>\n        </collision>\n        <visual name="box_visual">\n          <geometry>\n            <box>\n              <size>1 1 1</size>\n            </box>\n          </geometry>\n          <material>\n            <ambient>0.5 0.5 0.5 1</ambient>\n            <diffuse>0.8 0.3 0.3 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>1.0</mass>\n          <inertia>\n            <ixx>0.166667</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>0.166667</iyy>\n            <iyz>0</iyz>\n            <izz>0.166667</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    \x3c!-- Add a simple robot --\x3e\n    <include>\n      <uri>model://wheeled_robot</uri>\n      <pose>0 0 0.25 0 0 0</pose>\n    </include>\n  </world>\n</sdf>\n'})}),"\n",(0,o.jsx)(n.h3,{id:"ros-2-node-for-simulation-control",children:"ROS 2 Node for Simulation Control"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nfrom nav_msgs.msg import Odometry\nimport math\n\n\nclass SimulationController(Node):\n    """\n    Node that interfaces with Gazebo simulation to control a robot and process sensor data.\n    Demonstrates the integration between ROS 2 and simulation environments.\n    """\n\n    def __init__(self):\n        super().__init__(\'simulation_controller\')\n\n        # Publisher for velocity commands\n        self.cmd_vel_publisher = self.create_publisher(Twist, \'/cmd_vel\', 10)\n\n        # Subscriber for laser scan data\n        self.scan_subscriber = self.create_subscription(\n            LaserScan, \'/scan\', self.scan_callback, 10\n        )\n\n        # Subscriber for odometry data\n        self.odom_subscriber = self.create_subscription(\n            Odometry, \'/odom\', self.odom_callback, 10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)  # 10 Hz\n\n        # Robot state variables\n        self.current_position_x = 0.0\n        self.current_position_y = 0.0\n        self.current_yaw = 0.0\n        self.scan_data = None\n        self.obstacle_detected = False\n\n        self.get_logger().info(\'Simulation controller initialized\')\n\n    def scan_callback(self, msg):\n        """Process laser scan data to detect obstacles."""\n        self.scan_data = msg\n        # Check for obstacles in the forward direction (front 30 degrees)\n        front_scan_start = len(msg.ranges) // 2 - 15\n        front_scan_end = len(msg.ranges) // 2 + 15\n\n        min_distance = float(\'inf\')\n        for i in range(front_scan_start, front_scan_end):\n            if 0 < msg.ranges[i] < min_distance:\n                min_distance = msg.ranges[i]\n\n        self.obstacle_detected = min_distance < 1.0  # 1 meter threshold\n        if self.obstacle_detected:\n            self.get_logger().info(f\'Obstacle detected at {min_distance:.2f}m\')\n\n    def odom_callback(self, msg):\n        """Process odometry data to track robot position."""\n        self.current_position_x = msg.pose.pose.position.x\n        self.current_position_y = msg.pose.pose.position.y\n\n        # Extract yaw from quaternion (simplified for z-axis rotation)\n        orientation = msg.pose.pose.orientation\n        self.current_yaw = math.atan2(\n            2 * (orientation.w * orientation.z + orientation.x * orientation.y),\n            1 - 2 * (orientation.y * orientation.y + orientation.z * orientation.z)\n        )\n\n    def control_loop(self):\n        """Main control loop that processes sensor data and sends commands."""\n        cmd = Twist()\n\n        if self.obstacle_detected:\n            # Stop if obstacle detected\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n            self.get_logger().info(\'Obstacle detected, stopping robot\')\n        else:\n            # Move forward with slight random turn to explore\n            cmd.linear.x = 0.5  # 0.5 m/s\n            cmd.angular.z = 0.1 * math.sin(self.get_clock().now().nanoseconds / 1e9)  # Gentle turn\n\n        self.cmd_vel_publisher.publish(cmd)\n\n\ndef main(args=None):\n    """Main function to run the simulation controller."""\n    rclpy.init(args=args)\n\n    controller = SimulationController()\n\n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        controller.get_logger().info(\'Interrupt received, shutting down...\')\n    finally:\n        controller.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h3,{id:"launch-file-for-simulation-simulation_launchpy",children:"Launch File for Simulation (simulation_launch.py)"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import os\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\n\n\ndef generate_launch_description():\n    # Launch configuration variables\n    use_sim_time = LaunchConfiguration('use_sim_time')\n    world = LaunchConfiguration('world')\n\n    # Declare launch arguments\n    declare_use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='True',\n        description='Use simulation (Gazebo) clock if true'\n    )\n\n    declare_world = DeclareLaunchArgument(\n        'world',\n        default_value='simple_world.sdf',\n        description='Choose one of the world files from `/path/to/worlds`'\n    )\n\n    # Start Gazebo server\n    start_gazebo_server = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch',\n                'gzserver.launch.py'\n            ])\n        ]),\n        launch_arguments={'world': world}.items()\n    )\n\n    # Start Gazebo client\n    start_gazebo_client = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch',\n                'gzclient.launch.py'\n            ])\n        ])\n    )\n\n    # Robot state publisher\n    robot_state_publisher = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        name='robot_state_publisher',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    # Spawn robot in Gazebo\n    spawn_entity = Node(\n        package='gazebo_ros',\n        executable='spawn_entity.py',\n        arguments=[\n            '-topic', 'robot_description',\n            '-entity', 'wheeled_robot',\n            '-x', '0', '-y', '0', '-z', '0.25'\n        ],\n        output='screen'\n    )\n\n    # Our simulation controller\n    simulation_controller = Node(\n        package='simulation_examples',\n        executable='simulation_controller',\n        name='simulation_controller',\n        parameters=[{'use_sim_time': use_sim_time}],\n        output='screen'\n    )\n\n    # Create launch description and add actions\n    ld = LaunchDescription()\n\n    ld.add_action(declare_use_sim_time)\n    ld.add_action(declare_world)\n    ld.add_action(start_gazebo_server)\n    ld.add_action(start_gazebo_client)\n    ld.add_action(robot_state_publisher)\n    ld.add_action(spawn_entity)\n    ld.add_action(simulation_controller)\n\n    return ld\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Expected Output:"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"[INFO] [simulation_controller]: Simulation controller initialized\n[INFO] [simulation_controller]: Obstacle detected at 0.85m\n[INFO] [simulation_controller]: Obstacle detected, stopping robot\n[INFO] [simulation_controller]: Interrupt received, shutting down...\n"})}),"\n",(0,o.jsx)(n.h3,{id:"running-the-simulation",children:"Running the Simulation"}),"\n",(0,o.jsx)(n.p,{children:"To run this simulation setup:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: Start Gazebo with our world\nsource /opt/ros/humble/setup.bash\ngz sim -r simple_world.sdf\n\n# Terminal 2: Launch the ROS 2 nodes\nsource /opt/ros/humble/setup.bash\nros2 launch simulation_examples simulation_launch.py\n\n# Terminal 3: Monitor topics\nsource /opt/ros/humble/setup.bash\nros2 topic echo /scan\nros2 topic echo /odom\n"})}),"\n",(0,o.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsx)(n.h3,{id:"exercise-1-world-customization",children:"Exercise 1: World Customization"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Task"}),": Create a custom Gazebo world with multiple obstacles and goals."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Steps"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Modify the SDF world file to include multiple obstacles of different shapes"}),"\n",(0,o.jsx)(n.li,{children:"Add visual markers for goal locations"}),"\n",(0,o.jsx)(n.li,{children:"Create a more complex environment with narrow passages"}),"\n",(0,o.jsx)(n.li,{children:"Test your robot's navigation in the custom world"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Custom world loads without errors in Gazebo"}),"\n",(0,o.jsx)(n.li,{children:"Multiple obstacles and goals are properly positioned"}),"\n",(0,o.jsx)(n.li,{children:"Robot can navigate the environment safely"}),"\n",(0,o.jsx)(n.li,{children:"World file follows SDF standards"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"exercise-2-sensor-integration",children:"Exercise 2: Sensor Integration"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Task"}),": Integrate additional sensors into the simulation."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Steps"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Add a camera sensor to the robot model"}),"\n",(0,o.jsx)(n.li,{children:"Configure the camera to publish image data to ROS 2"}),"\n",(0,o.jsx)(n.li,{children:"Create a node that processes camera images"}),"\n",(0,o.jsx)(n.li,{children:"Test perception capabilities in simulation"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Camera sensor is properly configured in URDF/SDF"}),"\n",(0,o.jsx)(n.li,{children:"Image data is published to ROS 2 topics"}),"\n",(0,o.jsx)(n.li,{children:"Processing node receives and handles image data"}),"\n",(0,o.jsx)(n.li,{children:"Simulation reflects realistic sensor behavior"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"exercise-3-performance-comparison",children:"Exercise 3: Performance Comparison"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Task"}),": Compare simulation vs. real-world performance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Steps"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Implement a simple navigation algorithm in simulation"}),"\n",(0,o.jsx)(n.li,{children:"Document the algorithm's performance in simulation"}),"\n",(0,o.jsx)(n.li,{children:"Identify key differences between simulation and reality"}),"\n",(0,o.jsx)(n.li,{children:"Propose improvements for better sim-to-real transfer"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Algorithm performs well in simulation"}),"\n",(0,o.jsx)(n.li,{children:"Differences between sim and real are clearly identified"}),"\n",(0,o.jsx)(n.li,{children:"Improvement strategies are proposed"}),"\n",(0,o.jsx)(n.li,{children:"Understanding of sim-to-real challenges is demonstrated"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"Simulation is a cornerstone of Physical AI development, enabling safe, rapid, and cost-effective algorithm development. We've explored two primary simulation approaches: physics-accurate simulation (like Gazebo) for dynamics and control, and high-fidelity graphics simulation (like Unity) for perception tasks. The integration between ROS 2 and simulation environments allows developers to test complex robot behaviors in virtual worlds before deploying to physical hardware."}),"\n",(0,o.jsx)(n.p,{children:"We've implemented a complete simulation setup with a custom world, robot model, and control algorithms that demonstrate sensor processing and obstacle avoidance. The example showed how ROS 2 nodes can interface with simulation environments to create realistic testing scenarios."}),"\n",(0,o.jsx)(n.p,{children:"Understanding simulation is crucial for Physical AI systems as it bridges the gap between theoretical algorithms and real-world deployment. Effective use of simulation accelerates development, improves safety, and enables testing of scenarios that would be impractical or dangerous with physical robots."}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"Now that you understand the fundamentals of robotics simulation, the next chapter explores Gazebo in detail. You'll learn how to create complex simulation environments, configure physics properties, and integrate with ROS 2 for realistic robot testing."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Next Chapter"}),": Module 2, Chapter 2: Gazebo Physics Simulation"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>l});var s=i(6540);const o={},t=s.createContext(o);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);